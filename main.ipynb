{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Torch related package\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#cuda related package\n",
    "import torch.cuda\n",
    "import torch.backends.cudnn as cudnn\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other package\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run Annexe.ipynb #Good trick to launch another notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commentaire pour la suite (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le batch normalisation, il y en existe plusieurs, regarder exactement lequel on veut.\n",
    "\n",
    "On peut enlever le biais dans les convolutions avant la normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN (\n",
      "  (i2h): Linear (70 -> 20)\n",
      "  (h2o): Linear (20 -> 10)\n",
      "  (group0): Linear (20 -> 10)\n",
      "  (group1): Linear (20 -> 10)\n",
      "  (group2): Linear (20 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "\n",
    "    # you can also accept arguments in your model constructor\n",
    "    def __init__(self, data_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        input_size = data_size + hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        group = [0]*3\n",
    "        for i in range(3):\n",
    "            setattr(self, \"group\"+str(i), nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "\n",
    "    def forward(self, data, last_hidden):\n",
    "        input = torch.cat((data, last_hidden), 1)\n",
    "        hidden = self.i2h(input)\n",
    "        output = self.h2o(hidden)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "rnn = RNN(50, 20, 10)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2911\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(1)\n",
    "\n",
    "print(a)\n",
    "torch.bernoulli(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Bernoulli' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-51087721574f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mBernoulli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Bernoulli' is not defined"
     ]
    }
   ],
   "source": [
    "Bernoulli(torch.Tensor([0.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double_conv (\n",
      "  (conv): Sequential (\n",
      "    (0): Conv2d(4, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): Conv2d(5, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class double_conv(nn.Module):\n",
    "    '''(conv => BN => ReLU) * 2'''\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = f.ReLU(inplace=True)\n",
    "        return x\n",
    "print(double_conv(4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstConv (\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (dropOut): Dropout2d (p=0.5)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class firstConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    (3) = nMiddleput : number of features map after the first Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(firstConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.dropOut = nn.Dropout2d(0.5)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = firstConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityscapesLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GridNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class color():\n",
    "    convolution        = \"darkgoldenrod1\"\n",
    "    subSampling        = \"darkgoldenrod\" \n",
    "    fullConvolution    = \"firebrick1\"\n",
    "    upSampling         = \"firebrick\"\n",
    "    batchNormalization = \"deepskyblue3\"\n",
    "    relu               = \"darkolivegreen3\"\n",
    "    add                = \"bisque3\"\n",
    "    dropout            = \"darkviolet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstConv (\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU ()\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class firstConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(firstConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = firstConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convSequence (\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class convSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    (3) = dropFactor : number of features map after the first Convolution\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs,dropFactor):\n",
    "        super(convSequence, self).__init__()\n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = (torch.rand(1) > dropFactor)*x\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = convSequence(nInputs = 3,nOutputs = 3,dropFactor = 0.1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subSamplingSequence (\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = subSamplingSequence(nInputs = 3,nOutputs = 3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upSamplingSequence (\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convTranspose1): ConvTranspose2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class upSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that increase the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(upSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.convTranspose1 = nn.ConvTranspose2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.convTranspose1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = upSamplingSequence(nInputs = 3,nOutputs = 3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastConv (\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU ()\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class lastConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This class represente the last Convolution of the network before the prediction\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(lastConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = lastConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridNet (\n",
      "  (batchNormInitial): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (firstConv): firstConv (\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU ()\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (group0): Linear (4 -> 5)\n",
      "  (group1): Linear (4 -> 5)\n",
      "  (group2): Linear (4 -> 5)\n",
      "  (lastConv): lastConv (\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU ()\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class gridNet(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features maps for the input\n",
    "    (2) = nOutput : number of features maps for the output\n",
    "    (3) = nColumns : number of columns of the gridNet, this number should be divisible by two.\n",
    "    (4) = nFeatMaps : number of feature at each row of the gridNet\n",
    "    (5) = dropFactor : factor witch control the dropout of an entire bloc \n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs, nOutputs, nColumns, nFeatMaps, dropFactor):\n",
    "        super(gridNet, self).__init__()\n",
    "        \n",
    "        #A normalisation before any computation\n",
    "        self.batchNormInitial = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        # The first convolution before entering into the grid.\n",
    "        self.firstConv = firstConv(nInputs = nInputs, nOutputs = nFeatMaps[0])\n",
    "        \n",
    "        for i in range(nColumns):\n",
    "            for j in range()\n",
    "            setattr(self, \"group\"+str(i), nn.Linear(4, 5))\n",
    "        \n",
    "\n",
    "        # The last convolution before the result.\n",
    "        self.lastConv = lastConv(nInputs = nInputs, nOutputs = nFeatMaps[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "net = gridNet(nInputs = 3,nOutputs = 3, nColumns = 4, nFeatMaps = [3,6,12,24], dropFactor = 0.1)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
