{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Torch related package\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6021\n"
     ]
    }
   ],
   "source": [
    "#cuda related package\n",
    "import torch.cuda\n",
    "import torch.backends.cudnn as cudnn\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other package\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run Annexe.ipynb #Good trick to launch another notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commentaire pour la suite (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le batch normalisation, il y en existe plusieurs, regarder exactement lequel on veut.\n",
    "\n",
    "On peut enlever le biais dans les convolutions avant la normalisation\n",
    "\n",
    "Le diminution de la taille des images, pas clair cette division par deux....\n",
    "\n",
    "Change la fonction de cout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityscapesLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class color():\n",
    "    convolution        = \"darkgoldenrod1\"\n",
    "    subSampling        = \"darkgoldenrod\" \n",
    "    fullConvolution    = \"firebrick1\"\n",
    "    upSampling         = \"firebrick\"\n",
    "    batchNormalization = \"deepskyblue3\"\n",
    "    relu               = \"darkolivegreen3\"\n",
    "    add                = \"bisque3\"\n",
    "    dropout            = \"darkviolet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['road', 'sidewalk','building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign',\n",
    "           'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus','train', 'motorcycle', 'bicycle']\n",
    "number_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GridNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstConv(\n",
      "  (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class firstConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This is the first convolution used to enter into the grid.\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(firstConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = firstConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convSequence(\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU1): ReLU()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class convSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    (3) = dropFactor : Total Dropout on the entire Sequence, there is a probability p = dropFactor that\n",
    "        the residual is deleted.\n",
    "    This class reprensent a residual bloc that doesn't change number nor the size of the features maps\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs,dropFactor):\n",
    "        super(convSequence, self).__init__()\n",
    "        self.dropFactor = dropFactor\n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x_init):\n",
    "        x = self.batch1(x_init)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        # Small trick that transform boolean into integer\n",
    "        x = ((random.random() > self.dropFactor) * 1) * x\n",
    "        x = x_init + x\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = convSequence(nInputs = 3,nOutputs = 3,dropFactor = 0.1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subSamplingSequence(\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU()\n",
      "  (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU()\n",
      ")\n",
      "torch.Size([2, 6, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "network = subSamplingSequence(nInputs = 3,nOutputs = 6)\n",
    "print(network)\n",
    "a = torch.randn(2, 3, 7, 7)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upSamplingSequence(\n",
      "  (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU()\n",
      ")\n",
      "torch.Size([2, 3, 31, 31])\n"
     ]
    }
   ],
   "source": [
    "class upSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that increase the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(upSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.convTranspose1 = nn.ConvTranspose2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.convTranspose1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "network = upSamplingSequence(nInputs = 6,nOutputs = 3)\n",
    "print(network)\n",
    "a = torch.randn(2, 6, 16, 16)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastConv(\n",
      "  (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class lastConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This class represente the last Convolution of the network before the prediction\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(lastConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = lastConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridNet(\n",
      "  (batchNormInitial): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (firstConv): firstConv(\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence0_0to0_1): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence0_0to1_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence0_1to0_2): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence0_1to1_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence0_2to0_3): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence1_0to1_1): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence1_0to2_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence1_1to1_2): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence1_1to2_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence1_2to1_3): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence1_2to0_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence1_3to0_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence2_0to2_1): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence2_0to3_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence2_1to2_2): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (subSamplingSequence2_1to3_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence2_2to2_3): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence2_2to1_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence2_3to1_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence3_0to3_1): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence3_1to3_2): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence3_2to3_3): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence3_2to2_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (upSamplingSequence3_3to2_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d (24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (lastConv): lastConv(\n",
      "    (conv1): Conv2d (3, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv2): Conv2d (19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (batchNormFinal): BatchNorm2d(3, eps=1e-05, momentum=0, affine=True)\n",
      "  (logsoftmax1): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class gridNet(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features maps for the input\n",
    "    (2) = nOutput : number of features maps for the output\n",
    "    (3) = nColumns : number of columns of the gridNet, this number should be divisible by two.\n",
    "    It count the number of bloc +1\n",
    "    (4) = nFeatMaps : number of feature at each row of the gridNet\n",
    "    (5) = dropFactor : factor witch control the dropout of an entire bloc \n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs, nOutputs, nColumns, nFeatMaps, dropFactor):\n",
    "        super(gridNet, self).__init__()\n",
    "        \n",
    "        #Define some parameters as an attribut of the class\n",
    "        len_nfeatureMaps = len(nFeatMaps)\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        self.len_nfeatureMaps = len_nfeatureMaps\n",
    "        \n",
    "        # A normalisation before any computation\n",
    "        self.batchNormInitial = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        # The first convolution before entering into the grid.\n",
    "        self.firstConv = firstConv(nInputs = nInputs, nOutputs = nInputs)\n",
    "        \n",
    "        \n",
    "        # We create the Grid. We will creat conv and sub/up sequences with different name.\n",
    "        # The name is : \"sequenceName\" + starting position of the sequence(i,j) + \"to\" + ending position (k,l)\n",
    "        for i in range(len(nFeatMaps)):\n",
    "            for j in range(nColumns):\n",
    "                #We don t creat a residual bloc on the last column\n",
    "                if(j < (nColumns - 1)):\n",
    "                    setattr(self, \"convSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j + 1),\n",
    "                            convSequence(nFeatMaps[i], nFeatMaps[i],dropFactor))\n",
    "                \n",
    "                #We creat subSampling only on half of the grid and not in the last row\n",
    "                if(j < (nColumns // 2) and i < (len(nFeatMaps)-1)):\n",
    "                    setattr(self, \"subSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i + 1) + \"_\" + str(j),\n",
    "                            subSamplingSequence(nFeatMaps[i], nFeatMaps[i+1]))\n",
    "                \n",
    "                #Welook a the other half but not the first row\n",
    "                if(j >= (nColumns // 2) and i > 0):\n",
    "                    setattr(self, \"upSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i - 1) + \"_\" + str(j),\n",
    "                            upSamplingSequence(nFeatMaps[i], nFeatMaps[i-1]))\n",
    "\n",
    "        # The last convolution before the result.\n",
    "        self.lastConv = lastConv(nInputs = nFeatMaps[0], nOutputs = nOutputs)    \n",
    "    \n",
    "        self.batchNormFinal = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0,affine=True)\n",
    "        \n",
    "        self.logsoftmax1 = nn.LogSoftmax()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \"\"\"This function return the fusion of the actual value on (i,j) and the new data which come from the sampling\n",
    "    (1) = X_i_j : The value on the grid a the position (i,j)\n",
    "    (2) = SamplingSequence : The sampling that should be added to the point (i,j)\n",
    "    \"\"\"\n",
    "    def addTransform(self,X_i_j,SamplingSequence):\n",
    "        return(X_i_j + SamplingSequence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # A normalisation before any computation\n",
    "        x = self.batchNormInitial(x)\n",
    "        # The first convolution before entering into the grid.\n",
    "        x = self.firstConv(x)\n",
    "        \n",
    "        # X is the matrix that represente the values of the features maps at the point (i,j) in the grid.\n",
    "        X = [[0 for i in range(self.nColumns)] for j in range(self.len_nfeatureMaps)]\n",
    "        #The input of the grid is on (0,0)\n",
    "        X[0][0] = x\n",
    "        \n",
    "        # Looking on half of the grid, with sumsampling and convolution sequence\n",
    "        for j in range(self.nColumns//2):\n",
    "            for i in range(self.len_nfeatureMaps):\n",
    "                #For the first column, there is only subsampling\n",
    "                if(j > 0):\n",
    "                    #This syntaxe call self.conSequencei_(j-1)toi_j(X[i][j-1])\n",
    "                    X[i][j] = getattr(self,\"convSequence\"\n",
    "                                      + str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "                \n",
    "                # For the first row, there is only ConvSequence (residual bloc)\n",
    "                if(i > 0):\n",
    "                    X[i][j] = self.addTransform(X[i][j] , getattr(self,\"subSamplingSequence\"\n",
    "                                                + str(i-1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i-1][j]))\n",
    "\n",
    "        # Looking on the other half of the grid\n",
    "        for j in range(self.nColumns//2,self.nColumns):\n",
    "            for i in range(self.len_nfeatureMaps-1,-1,-1):\n",
    "                X[i][j] = getattr(self,\"convSequence\" +\n",
    "                                      str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "\n",
    "                \n",
    "                # There is no upSampling on the last row\n",
    "                if(i < (self.len_nfeatureMaps - 1)):\n",
    "                    X[i][j] = self.addTransform(X[i][j], getattr(self,\"upSamplingSequence\"\n",
    "                                                + str(i+1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i+1][j]))\n",
    "\n",
    "        x_final = self.lastConv(X[0][self.nColumns - 1])\n",
    "\n",
    "        if(False):\n",
    "            print(\"Size of different X_i_j\")\n",
    "            for i1,i2 in enumerate(X):\n",
    "                for j1,j2 in enumerate(i2):\n",
    "                    print(\"Dim(X(\" + str(i1) + \")(\" + str(j1) + \")) : \",j2.size())\n",
    "             \n",
    "\n",
    "        return x_final\n",
    "\n",
    "\n",
    "network = gridNet(nInputs = 3,nOutputs = number_classes, nColumns = 4, nFeatMaps = [3,6,12,24], dropFactor = 0.1)\n",
    "print(network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self,nColumns, nFeatMaps, dropFactor,learning_rate,number_classes, beta1, beta2,epsilon,\n",
    "                weight_decay,width_image, height_image,nFeatureMaps_init,batch_size):\n",
    "        super(Parameters, self).__init__()\n",
    "        # Image\n",
    "        self.number_classes = number_classes\n",
    "        self.width_image = width_image\n",
    "        self.height_image = height_image\n",
    "        # Number of feature map at the begining, if RGB image it would be 3\n",
    "        self.nFeatureMaps_init = nFeatureMaps_init\n",
    "        \n",
    "        # GridNet\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        \n",
    "        # Learning\n",
    "        self.dropFactor = dropFactor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the loss function between the y_train_estimated and y_train\"\"\"\n",
    "def criterion(y_train_estimated, y_train):\n",
    "    nllcrit = nn.NLLLoss2d()\n",
    "    return nllcrit(F.log_softmax(y_train_estimated, dim = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train return\n",
    "    (0) = parameters : list of parameters of the network\n",
    "    (1) = x_train : inputs of the training set\n",
    "    (2) = y_train : outputs of the training set\n",
    "    (3) = x_validation : inputs of the validation set\n",
    "    (4) = y_validation : outputs of the validation set\n",
    "\"\"\"\n",
    "def train(parameters,network,x_train,y_train):\n",
    "     \n",
    "    # create your optimizer\n",
    "    optimizer = optim.Adam(params = network.parameters(), lr=parameters.learning_rate,\n",
    "                           betas = (parameters.beta1, parameters.beta2),\n",
    "                           eps = parameters.epsilon, weight_decay = parameters.weight_decay)\n",
    "\n",
    "    # zero the gradient buffers\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(2):\n",
    "        # Compute the forward function\n",
    "        y_train_estimated = network(x_train)\n",
    "        \n",
    "        #Get the error\n",
    "        loss = criterion(y_train_estimated, y_train)\n",
    "        \n",
    "        #Compute the backward function\n",
    "        loss.backward()\n",
    "        \n",
    "        # Does the update according to the optimizer define above\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        print(loss.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For filelist reading\n",
    "\n",
    "def iou(pred, target, n_classes = 19):\n",
    "    ious = []\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "\n",
    "    # Ignore IoU for background class (\"0\")\n",
    "    for cls in range(0, n_classes):  # This goes from 1:n_classes-1 -> class \"0\" is ignored\n",
    "        pred_inds = pred == cls\n",
    "        target_inds = target == cls\n",
    "        intersection = (pred_inds[target_inds]).long().sum().data.cpu()[0]  # Cast to long to prevent overflows\n",
    "        union = pred_inds.long().sum().data.cpu()[0] + target_inds.long().sum().data.cpu()[0] - intersection\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # If there is no ground truth, do not include in evaluation\n",
    "        else:\n",
    "            ious.append(float(intersection) / float(max(union, 1)))\n",
    "    return ious\n",
    "\n",
    "\n",
    "def evaluate_performance(net):\n",
    "    # Dataloader for test data\n",
    "    batch_size = 1  \n",
    "    filelist_name_test = '/path/to/my/test/filelist.txt'\n",
    "    data_root_test = '/path/to/my/data/'\n",
    "    dset_test = myPytorchDatasetClass.CustomDataset(filelist_name_test, data_root_test)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=dset_test,  \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=True)\n",
    "    data_info = pd.read_csv(filelist_name_test, header=None)\n",
    "    num_test_files = data_info.shape[0]  \n",
    "    sample_size = num_test_files\n",
    "\n",
    "    # Containers for results\n",
    "    preds = Variable(torch.zeros((sample_size, 60, 36, 60)))\n",
    "    gts = Variable(torch.zeros((sample_size, 60, 36, 60)))\n",
    "\n",
    "    dataiter = iter(test_loader) \n",
    "    for i in xrange(sample_size):\n",
    "        images, labels, filename = dataiter.next()\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels)\n",
    "        gts[i:i+batch_size, :, :, :] = labels\n",
    "        outputs = net(images)\n",
    "        outputs = outputs.permute(0, 2, 3, 4, 1).contiguous()\n",
    "        val, pred = torch.max(outputs, 4)\n",
    "        preds[i:i+batch_size, :, :, :] = pred.cpu()\n",
    "    acc = iou(preds, gts)\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Test function : IoU\n",
    "    return a matrix of confusion and the error given by IoU multi dimensional\n",
    "\"\"\"\n",
    "def IoU(y_train_estimated, y_train):\n",
    "    \n",
    "    #We keep only the higest value, which is the prediction\n",
    "    pred = torch.max(y_train_estimated, dim=1)[1]\n",
    "\n",
    "    confusion_matrix = [[0] * parameters.number_classes for i in range(parameters.number_classes)]\n",
    "    \n",
    "    #For each classes : [0] = TP [1] = FP [2] = FN\n",
    "    IoU_each_classes = [[0] * parameters.number_classes for i in range(3)]\n",
    "\n",
    "    pred = pred.view(-1)\n",
    "    target = y_train.view(-1)\n",
    "\n",
    "    # Double loop over the number of classes at each iteration we add the intersection\n",
    "    for cls1 in range(parameters.number_classes):\n",
    "        pred_inds = pred == cls1\n",
    "        for cls2 in range(parameters.number_classes):\n",
    "            target_inds = target == cls2\n",
    "            intersection = (pred_inds*target_inds).long().sum().data.cpu()[0]\n",
    "            confusion_matrix[cls1][cls2] = intersection\n",
    "            if(cls1 == cls2):\n",
    "                IoU_each_classes[0][cls1] = intersection\n",
    "            else if(cls1 < cls2):\n",
    "                IoU_each_classes[1][cls1] = IoU_each_classes[1][cls1] + intersection\n",
    "                IoU_each_classes[2][cls2] = IoU_each_classes[2][cls1] + intersection\n",
    "            IoU_each_classes_total = IoU_each_classes[]\n",
    "    return(confusion_matrix,IoU_each_classes,(1/parameters.number_classes)*sum(IoU_each_classes))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,.,.) = \n",
      "  6.7469  3.3302  2.9419  1.3961  1.6629  0.4780  3.7841\n",
      "  3.7203  3.2356  3.4893  1.9484  0.3709  7.2597  0.1774\n",
      "  2.8430  6.4990  3.4820  6.5861  1.2738  2.9705  2.8868\n",
      "  3.7905  2.3945  7.1523  3.7218  0.6620  4.3578  0.2424\n",
      "  2.9820  7.0475  2.0394  7.4263  0.1736  1.4244  3.6486\n",
      "  6.1596  1.9681  3.7703  4.9852  0.6826  5.4199  0.5896\n",
      "  7.0447  3.8244  7.2618  2.6180  7.8172  2.8268  1.7282\n",
      "\n",
      "(1 ,.,.) = \n",
      "  7.2862  1.0149  0.5524  7.8517  6.3418  5.6362  4.6631\n",
      "  5.4637  0.8537  1.5049  1.5267  6.2524  4.8739  0.6230\n",
      "  5.1672  4.0172  1.2303  1.7974  2.2285  4.1835  5.9027\n",
      "  4.5046  2.8441  6.3969  0.9147  3.6551  0.3610  5.4970\n",
      "  3.9551  2.8237  6.2632  7.8535  7.9083  3.7990  4.7695\n",
      "  7.0250  1.1793  7.1424  4.3913  2.5463  4.3673  1.2831\n",
      "  0.4391  4.5048  1.1487  4.0744  4.7350  4.3373  5.6660\n",
      "[torch.FloatTensor of size 2x7x7]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "   6   3   2   1   1   0   3\n",
      "   3   3   3   1   0   7   0\n",
      "   2   6   3   6   1   2   2\n",
      "   3   2   7   3   0   4   0\n",
      "   2   7   2   7   0   1   3\n",
      "   6   1   3   4   0   5   0\n",
      "   7   3   7   2   7   2   1\n",
      "\n",
      "(1 ,.,.) = \n",
      "   7   1   0   7   6   5   4\n",
      "   5   0   1   1   6   4   0\n",
      "   5   4   1   1   2   4   5\n",
      "   4   2   6   0   3   0   5\n",
      "   3   2   6   7   7   3   4\n",
      "   7   1   7   4   2   4   1\n",
      "   0   4   1   4   4   4   5\n",
      "[torch.LongTensor of size 2x7x7]\n",
      "\n",
      "torch.Size([2, 7, 7])\n",
      "torch.Size([2, 3, 7, 7])\n",
      "2.125814437866211\n",
      "2.0199198722839355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[9, 4, 0, 3, 2, 2, 1, 2],\n",
       " [0, 1, 0, 0, 0, 0, 1, 2],\n",
       " [1, 3, 7, 3, 3, 1, 1, 4],\n",
       " [0, 0, 1, 3, 1, 3, 1, 2],\n",
       " [0, 0, 2, 1, 1, 0, 0, 2],\n",
       " [4, 7, 3, 3, 6, 1, 4, 1],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "random.seed(465)\n",
    "\n",
    "batch_size = 2\n",
    "image_size = 7\n",
    "parameters = Parameters(nColumns = 4, learning_rate=0.01, nFeatMaps = [3,6],dropFactor = 0.1,\n",
    "                        number_classes = 8, weight_decay = 5*10**(-6), beta1 = 0.9,\n",
    "                        beta2 = 0.999, epsilon = 1*10**(-8), width_image = image_size, height_image = image_size,\n",
    "                        nFeatureMaps_init = len(x_train[0,:,0,0]), batch_size = batch_size)\n",
    "\n",
    "\n",
    "a = torch.randn(batch_size, 3, image_size, image_size)\n",
    "\n",
    "b = (torch.rand(batch_size,image_size,image_size)*1000)%parameters.number_classes\n",
    "print(b)\n",
    "\n",
    "x_train = Variable(a)\n",
    "y_train = Variable(b).long()\n",
    "print(y_train)\n",
    "print(y_train.size())\n",
    "print(x_train.size())\n",
    "\n",
    "x_validation = Variable(b)\n",
    "y_validation = Variable(b)\n",
    "\n",
    "# Define the GridNet\n",
    "network = gridNet(nInputs = parameters.nFeatureMaps_init,nOutputs = parameters.number_classes, nColumns = parameters.nColumns,\n",
    "                      nFeatMaps = parameters.nFeatMaps, dropFactor = parameters.dropFactor)\n",
    "train(network = network, parameters = parameters, x_train=x_train, y_train=y_train)\n",
    "\n",
    "y_train_estimated = network(x_train)\n",
    "\n",
    "a,b = IoU(y_train_estimated,y_train)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 3 elements not 19",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-235-d486c58c9e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                       nFeatMaps = parameters.nFeatMaps, dropFactor = parameters.dropFactor)\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0my_train_estimated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_estimated\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-43ea5f6cd13c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# A normalisation before any computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchNormInitial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;31m# The first convolution before entering into the grid.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirstConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m         return F.batch_norm(\n\u001b[1;32m     36\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             self.training, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: running_mean should contain 3 elements not 19"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 3, 4, 4)\n",
    "parameters.number_classes = 3\n",
    "b = torch.rand(2,4,4)*0\n",
    "x_train = Variable(a)\n",
    "y_train = Variable(b).long()\n",
    "\n",
    "network = gridNet(nInputs = parameters.nFeatureMaps_init,nOutputs = parameters.number_classes, nColumns = parameters.nColumns,\n",
    "                      nFeatMaps = parameters.nFeatMaps, dropFactor = parameters.dropFactor)\n",
    "\n",
    "y_train_estimated = network(x_train)\n",
    "\n",
    "a = IoU(y_train_estimated,y_train)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Graphical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'subSamplingSequence' object has no attribute 'Seque'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e1c0a669babc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubSamplingSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnInputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-e1c0a669babc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nInputs, nOutputs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnOutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubSamplingSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 238\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'subSamplingSequence' object has no attribute 'Seque'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable, Function\n",
    "from collections import defaultdict\n",
    "import graphviz\n",
    "\n",
    "\"\"\"\n",
    "This is a rather distorted implementation of graph visualization in PyTorch.\n",
    "This implementation is distorted because PyTorch's autograd is undergoing refactoring right now.\n",
    "- neither func.next_functions nor func.previous_functions can be relied upon\n",
    "- BatchNorm's C backend does not follow the python Function interface\n",
    "- I'm not even sure whether to use var.creator or var.grad_fn (apparently the source tree and wheel builds use different\n",
    "  interface now)\n",
    "As a result, we are forced to manually trace the graph, using 2 redundant mechanisms:\n",
    "- Function.__call__: this allows us to trace all Function creations. Function corresponds to Op in TF\n",
    "- Module.forward_hook: this is needed because the above method doesn't work for BatchNorm, as the current C backend does\n",
    "  not follow the Python Function interface. \n",
    "To do graph visualization, follow these steps:\n",
    "1. register hooks on model: register_vis_hooks(model)\n",
    "2. pass data through model: output = model(input)\n",
    "3. remove hooks           : remove_vis_hooks()\n",
    "4. perform visualization  : save_visualization(name, format='svg') # name is a string without extension\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "old_function__call__ = Function.__call__\n",
    "\n",
    "def register_creator(inputs, creator, output):\n",
    "    \"\"\"\n",
    "    In the forward pass, our Function.__call__ and BatchNorm.forward_hook both call this method to register the creators\n",
    "    inputs: list of input variables\n",
    "    creator: one of\n",
    "        - Function\n",
    "        - BatchNorm module\n",
    "    output: a single output variable\n",
    "    \"\"\"\n",
    "    cid = id(creator)\n",
    "    oid = id(output)\n",
    "    if oid in vars: \n",
    "        return\n",
    "    # connect creator to input\n",
    "    for input in inputs:\n",
    "        iid = id(input)\n",
    "        func_trace[cid][iid] = input\n",
    "        # register input\n",
    "        vars[iid] = input\n",
    "    # connect output to creator\n",
    "    assert type(output) not in [tuple, list, dict]\n",
    "    var_trace[oid][cid] = creator\n",
    "    # register creator and output and all inputs\n",
    "    vars[oid] = output\n",
    "    funcs[cid] = creator\n",
    "\n",
    "hooks = []\n",
    "\n",
    "def register_vis_hooks(model):\n",
    "    global var_trace, func_trace, vars, funcs\n",
    "    remove_vis_hooks()\n",
    "    var_trace  = defaultdict(lambda: {})     # map oid to {cid:creator}\n",
    "    func_trace = defaultdict(lambda: {})     # map cid to {iid:input}\n",
    "    vars  = {}                               # map vid to Variable/Parameter\n",
    "    funcs = {}                               # map cid to Function/BatchNorm module\n",
    "    hooks = []                               # contains the forward hooks, needed for hook removal\n",
    "\n",
    "    def hook_func(module, inputs, output):\n",
    "        assert 'BatchNorm' in mod.__class__.__name__        # batchnorms don't have shared superclass\n",
    "        inputs = list(inputs)\n",
    "        for p in [module.weight, module.bias]:\n",
    "            if p is not None:\n",
    "                inputs.append(p)\n",
    "        register_creator(inputs, module, output)\n",
    "\n",
    "    for mod in model.modules():\n",
    "        if 'BatchNorm' in mod.__class__.__name__:           # batchnorms don't have shared superclass\n",
    "            hook = mod.register_forward_hook(hook_func)\n",
    "            hooks.append(hook)\n",
    "\n",
    "    def new_function__call__(self, *args, **kwargs):\n",
    "        inputs =  [a for a in args            if isinstance(a, Variable)]\n",
    "        inputs += [a for a in kwargs.values() if isinstance(a, Variable)]\n",
    "        output = old_function__call__(self, *args, **kwargs)\n",
    "        register_creator(inputs, self, output)\n",
    "        return output\n",
    "\n",
    "    Function.__call__ = new_function__call__\n",
    "\n",
    "\n",
    "def remove_vis_hooks():\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    Function.__call__ = old_function__call__\n",
    "\n",
    "\n",
    "def save_visualization(name, format='svg'):\n",
    "    g = graphviz.Digraph(format=format)\n",
    "    def sizestr(var):\n",
    "        size = [int(i) for i in list(var.size())]\n",
    "        return str(size)\n",
    "    # add variable nodes\n",
    "    for vid, var in vars.iteritems():\n",
    "        if isinstance(var, nn.Parameter):\n",
    "            g.node(str(vid), label=sizestr(var), shape='ellipse', style='filled', fillcolor='red')\n",
    "        elif isinstance(var, Variable):\n",
    "            g.node(str(vid), label=sizestr(var), shape='ellipse', style='filled', fillcolor='lightblue')\n",
    "        else:\n",
    "            assert False, var.__class__\n",
    "    # add creator nodes\n",
    "    for cid in func_trace:\n",
    "        creator = funcs[cid]\n",
    "        g.node(str(cid), label=str(creator.__class__.__name__), shape='rectangle', style='filled', fillcolor='orange')\n",
    "    # add edges between creator and inputs\n",
    "    for cid in func_trace:\n",
    "        for iid in func_trace[cid]:\n",
    "            g.edge(str(iid), str(cid))\n",
    "    # add edges between outputs and creators\n",
    "    for oid in var_trace:\n",
    "        for cid in var_trace[oid]:\n",
    "            g.edge(str(cid), str(oid))\n",
    "    g.render(name)\n",
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        self.Seque\n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "network = subSamplingSequence(nInputs = 3,nOutputs = 6)\n",
    "print(network)\n",
    "a = torch.randn(2, 3, 7, 7)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())\n",
    "\n",
    "def visualize(a,network):\n",
    "    global recon\n",
    "    inputs = Variable(a)\n",
    "    register_vis_hooks(network)\n",
    "    recon = network(inputs)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')\n",
    "    \n",
    "visualize(a,network)\n",
    "#resnet18 = models.resnet18()\n",
    "#y = resnet18(inputs)\n",
    "# print(y)\n",
    "\n",
    "g = make_dot(out)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import re\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "def make_dot(var):\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if isinstance(var, Variable):\n",
    "                value = '('+(', ').join(['%d'% v for v in var.size()])+')'\n",
    "                dot.node(str(id(var)), str(value), fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'previous_functions'):\n",
    "                for u in var.previous_functions:\n",
    "                    dot.edge(str(id(u[0])), str(id(var)))\n",
    "                    add_nodes(u[0])\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
