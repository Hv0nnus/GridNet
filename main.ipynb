{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Torch related package\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#cuda related package\n",
    "import torch.cuda\n",
    "import torch.backends.cudnn as cudnn\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other package\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%run Annexe.ipynb #Good trick to launch another notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commentaire pour la suite (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le batch normalisation, il y en existe plusieurs, regarder exactement lequel on veut.\n",
    "\n",
    "On peut enlever le biais dans les convolutions avant la normalisation\n",
    "\n",
    "Le diminution de la taille des images, pas clair cette division par deux...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrainement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CityscapesLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class color():\n",
    "    convolution        = \"darkgoldenrod1\"\n",
    "    subSampling        = \"darkgoldenrod\" \n",
    "    fullConvolution    = \"firebrick1\"\n",
    "    upSampling         = \"firebrick\"\n",
    "    batchNormalization = \"deepskyblue3\"\n",
    "    relu               = \"darkolivegreen3\"\n",
    "    add                = \"bisque3\"\n",
    "    dropout            = \"darkviolet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = ['road', 'sidewalk','building', 'wall', 'fence', 'pole', 'traffic light', 'traffic sign',\n",
    "           'vegetation', 'terrain', 'sky', 'person', 'rider', 'car', 'truck', 'bus','train', 'motorcycle', 'bicycle']\n",
    "number_classes = len(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GridNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstConv (\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU ()\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class firstConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This is the first convolution used to enter into the grid.\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(firstConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = firstConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convSequence (\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class convSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    (3) = dropFactor : Total Dropout on the entire Sequence, there is a probability p = dropFactor that\n",
    "        the residual is deleted.\n",
    "    This class reprensent a residual bloc that doesn't change number nor the size of the features maps\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs,dropFactor):\n",
    "        super(convSequence, self).__init__()\n",
    "        self.dropFactor = dropFactor\n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, x_init):\n",
    "        x = self.batch1(x_init)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        #Small trick : *1 is usefull to transforme Boolean into Integer\n",
    "        x = ((random.random() > self.dropFactor)*1)*x\n",
    "        x = x_init + x\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = convSequence(nInputs = 3,nOutputs = 3,dropFactor = 0.1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subSamplingSequence (\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n",
      "torch.Size([2, 6, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "network = subSamplingSequence(nInputs = 3,nOutputs = 6)\n",
    "print(network)\n",
    "a = torch.randn(2, 3, 7, 7)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upSamplingSequence (\n",
      "  (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (convTranspose1): ConvTranspose2d(6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (ReLU1): ReLU ()\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (ReLU2): ReLU ()\n",
      ")\n",
      "torch.Size([2, 3, 31, 31])\n"
     ]
    }
   ],
   "source": [
    "class upSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that increase the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(upSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.convTranspose1 = nn.ConvTranspose2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.convTranspose1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "network = upSamplingSequence(nInputs = 6,nOutputs = 3)\n",
    "print(network)\n",
    "a = torch.randn(2, 6, 16, 16)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastConv (\n",
      "  (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU ()\n",
      "  (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU ()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class lastConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This class represente the last Convolution of the network before the prediction\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(lastConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "net = lastConv(nInputs = 3,nOutputs = 3)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridNet (\n",
      "  (batchNormInitial): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (firstConv): firstConv (\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU ()\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence0_0to0_1): convSequence (\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence0_0to1_0): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence0_1to0_2): convSequence (\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence0_1to1_1): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence0_2to0_3): convSequence (\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence1_0to1_1): convSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence1_0to2_0): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence1_1to1_2): convSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence1_1to2_1): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence1_2to1_3): convSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence1_2to0_2): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence1_3to0_3): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence2_0to2_1): convSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence2_0to3_0): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence2_1to2_2): convSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (subSamplingSequence2_1to3_1): subSamplingSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence2_2to2_3): convSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence2_2to1_2): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence2_3to1_3): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence3_0to3_1): convSequence (\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence3_1to3_2): convSequence (\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (convSequence3_2to3_3): convSequence (\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv1): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence3_2to2_2): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (upSamplingSequence3_3to2_3): upSamplingSequence (\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (convTranspose1): ConvTranspose2d(24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (ReLU1): ReLU ()\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (lastConv): lastConv (\n",
      "    (conv1): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU ()\n",
      "    (conv2): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU ()\n",
      "  )\n",
      "  (batchNormFinal): BatchNorm2d(3, eps=1e-05, momentum=0, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class gridNet(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features maps for the input\n",
    "    (2) = nOutput : number of features maps for the output\n",
    "    (3) = nColumns : number of columns of the gridNet, this number should be divisible by two.\n",
    "    It count the number of bloc +1\n",
    "    (4) = nFeatMaps : number of feature at each row of the gridNet\n",
    "    (5) = dropFactor : factor witch control the dropout of an entire bloc \n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs, nOutputs, nColumns, nFeatMaps, dropFactor):\n",
    "        super(gridNet, self).__init__()\n",
    "        \n",
    "        #Define some parameters as an attribut of the class\n",
    "        len_nfeatureMaps = len(nFeatMaps)\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        self.len_nfeatureMaps = len_nfeatureMaps\n",
    "        \n",
    "        # A normalisation before any computation\n",
    "        self.batchNormInitial = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        # The first convolution before entering into the grid.\n",
    "        self.firstConv = firstConv(nInputs = nInputs, nOutputs = nFeatMaps[0])\n",
    "        \n",
    "        \n",
    "        # We create the Grid. We will creat conv and sub/up sequences with different name.\n",
    "        # The name is : \"sequenceName\" + starting position of the sequence(i,j) + \"to\" + ending position (k,l)\n",
    "        for i in range(len(nFeatMaps)):\n",
    "            for j in range(nColumns):\n",
    "                #We don t creat a residual bloc on the last column\n",
    "                if(j < (nColumns - 1)):\n",
    "                    setattr(self, \"convSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j + 1),\n",
    "                            convSequence(nFeatMaps[i], nFeatMaps[i],dropFactor))\n",
    "                \n",
    "                #We creat subSampling only on half of the grid and not in the last row\n",
    "                if(j < (nColumns // 2) and i < (len(nFeatMaps)-1)):\n",
    "                    setattr(self, \"subSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i + 1) + \"_\" + str(j),\n",
    "                            subSamplingSequence(nFeatMaps[i], nFeatMaps[i+1]))\n",
    "                \n",
    "                #Welook a the other half but not the first row\n",
    "                if(j >= (nColumns // 2) and i > 0):\n",
    "                    setattr(self, \"upSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i - 1) + \"_\" + str(j),\n",
    "                            upSamplingSequence(nFeatMaps[i], nFeatMaps[i-1]))\n",
    "\n",
    "        # The last convolution before the result.\n",
    "        self.lastConv = lastConv(nInputs = nFeatMaps[0], nOutputs = nOutputs)    \n",
    "    \n",
    "        self.batchNormFinal = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0,affine=True)\n",
    "    \n",
    "    \"\"\"This function return the fusion of the actual value on (i,j) and the new data which come from the sampling\n",
    "    (1) = X_i_j : The value on the grid a the position (i,j)\n",
    "    (2) = SamplingSequence : The sampling that should be added to the point (i,j)\n",
    "    \"\"\"\n",
    "    def addTransform(self,X_i_j,SamplingSequence):\n",
    "        return(X_i_j + SamplingSequence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # A normalisation before any computation\n",
    "        x = self.batchNormInitial(x)\n",
    "        # The first convolution before entering into the grid.\n",
    "        x = self.firstConv(x)\n",
    "        \n",
    "        # X is the matrix that represente the values of the features maps at the point (i,j) in the grid.\n",
    "        X = [[0 for i in range(self.nColumns)] for j in range(self.len_nfeatureMaps)]\n",
    "        #The input of the grid is on (0,0)\n",
    "        X[0][0] = x\n",
    "        \n",
    "        # Looking on half of the grid, with sumsampling and convolution sequence\n",
    "        for j in range(self.nColumns//2):\n",
    "            for i in range(self.len_nfeatureMaps):\n",
    "                #For the first column, there is only subsampling\n",
    "                if(j > 0):\n",
    "                    #This syntaxe call self.conSequencei_(j-1)toi_j(X[i][j-1])\n",
    "                    X[i][j] = getattr(self,\"convSequence\"\n",
    "                                      + str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "                \n",
    "                # For the first row, there is only ConvSequence (residual bloc)\n",
    "                if(i > 0):\n",
    "                    X[i][j] = self.addTransform(X[i][j] , getattr(self,\"subSamplingSequence\"\n",
    "                                                + str(i-1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i-1][j]))\n",
    "\n",
    "        # Looking on the other half of the grid\n",
    "        for j in range(self.nColumns//2,self.nColumns):\n",
    "            for i in range(self.len_nfeatureMaps-1,-1,-1):\n",
    "                X[i][j] = getattr(self,\"convSequence\" +\n",
    "                                      str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "\n",
    "                \n",
    "                # There is no upSampling on the last row\n",
    "                if(i < (self.len_nfeatureMaps - 1)):\n",
    "                    X[i][j] = self.addTransform(X[i][j], getattr(self,\"upSamplingSequence\"\n",
    "                                                + str(i+1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i+1][j]))\n",
    "\n",
    "        x_final = self.lastConv(X[0][self.nColumns - 1])\n",
    "        #x_final = self.batchNormFinal(x_final)\n",
    "        if(False):\n",
    "            print(\"Size of different X_i_j\")\n",
    "            for i1,i2 in enumerate(X):\n",
    "                for j1,j2 in enumerate(i2):\n",
    "                    print(\"Dim(X(\" + str(i1) + \")(\" + str(j1) + \")) : \",j2.size())\n",
    "                    \n",
    "        \n",
    "        return x_final\n",
    "\n",
    "\n",
    "network = gridNet(nInputs = 3,nOutputs = 3, nColumns = 4, nFeatMaps = [3,6,12,24], dropFactor = 0.1)\n",
    "print(network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self,nColumns, nFeatMaps, dropFactor,learning_rate):\n",
    "        super(Parameters, self).__init__()\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        self.dropFactor = dropFactor\n",
    "        self.learning_rate = learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 0\n",
      " 4\n",
      "[torch.LongTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = torch.LongTensor([1, 0, 4])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossEntropyMultiClass(y_train_estimated, y_train):\n",
    "    #print(torch.log(y_train_estimated))\n",
    "    return torch.sum(y_train * torch.log(y_train_estimated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train return\n",
    "    (0) = parameters : list of parameters of the network\n",
    "    (1) = x_train : inputs of the training set\n",
    "    (2) = y_train : outputs of the training set\n",
    "    (3) = x_validation : inputs of the validation set\n",
    "    (4) = y_validation : outputs of the validation set\n",
    "\"\"\"\n",
    "def train(parameters,x_train,y_train):\n",
    "    \n",
    "    nFeatureMaps_init = len(x_train[0,:,0,0])\n",
    "    print(nFeatureMaps_init)\n",
    "    network = gridNet(nInputs = nFeatureMaps_init,nOutputs = nFeatureMaps_init, nColumns = 4,\n",
    "                      nFeatMaps = [3,6,12,24], dropFactor = 0.1)\n",
    "\n",
    "    #criterion = nn.MSELoss()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # create your optimizer\n",
    "    optimizer = optim.SGD(network.parameters(), lr=parameters.learning_rate)\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()   # zero the gradient buffers\n",
    "    for i in range(1):\n",
    "        y_train_estimated = network(x_train)\n",
    "        #print(y_train_estimated)\n",
    "        print(torch.sum(y_train_estimated,1))\n",
    "        #y_train_estimated = y_train_estimated.view(number_classes,10,33,33)\n",
    "\n",
    "        #loss = criterion(y_train_estimated, y_train)\n",
    "        loss = CrossEntropyMultiClass(y_train_estimated, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 19, 33, 33])\n"
     ]
    }
   ],
   "source": [
    "print(a.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 33, 33])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mean(a,1).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0 ,0 ,.,.) = \n",
      " -0.5060  0.3355 -0.0926 -1.1888\n",
      " -0.0631 -0.6041  0.7762  1.3932\n",
      "  0.8904  0.7731 -1.3304  0.0306\n",
      " -1.2425 -0.5525 -0.7996  2.3915\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.1181 -0.0935 -0.6731 -0.2692\n",
      "  1.0446 -0.4981  0.4258 -0.9175\n",
      "  0.2209 -0.7444 -0.8104  0.5128\n",
      " -0.2682  1.7114  1.2250 -0.0911\n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -0.7856  0.0196 -0.4976  1.3871\n",
      " -0.8296 -0.7159  0.6417 -0.5197\n",
      "  1.0163 -1.2439 -1.3027 -0.4422\n",
      "  0.3081  1.2636 -0.9944  2.0035\n",
      "\n",
      "(1 ,1 ,.,.) = \n",
      " -0.6033  0.4444  0.5580 -0.7985\n",
      "  1.0743  1.5524 -0.5163 -0.3325\n",
      "  0.4065 -1.7210  0.7766  1.5179\n",
      "  1.4348  0.8710 -0.6408 -0.9367\n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -0.8687 -1.5544 -0.1717 -0.6499\n",
      " -1.9172  0.4544 -1.4561 -1.4480\n",
      " -0.1442 -0.0672 -0.3175  0.4960\n",
      " -0.6759  1.6532  1.0313  0.1143\n",
      "\n",
      "(2 ,1 ,.,.) = \n",
      " -0.9479  1.3732  2.0844 -1.2347\n",
      " -0.9895 -0.7566  0.1692 -0.3346\n",
      "  0.7447 -0.2999  0.3205  1.9147\n",
      " -0.8564  0.7971 -2.7102  0.5783\n",
      "[torch.FloatTensor of size 3x2x4x4]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "torch.norm received an invalid combination of arguments - got (torch.FloatTensor, dim=int, keepDim=bool, p=int), but expected one of:\n * (torch.FloatTensor source)\n * (torch.FloatTensor source, float p)\n * (torch.FloatTensor source, float p, int dim)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-f963b31df25e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepDim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepDim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: torch.norm received an invalid combination of arguments - got (torch.FloatTensor, dim=int, keepDim=bool, p=int), but expected one of:\n * (torch.FloatTensor source)\n * (torch.FloatTensor source, float p)\n * (torch.FloatTensor source, float p, int dim)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,2,4,4)\n",
    "print(a)\n",
    "print(torch.norm(a, p=2, dim=1,keepDim = True).size())\n",
    "print(torch.norm(a, p=2, dim=1,keepDim = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  7.4741e-01  1.2831e+00 -8.4799e-02  ...   8.4326e-01  2.0882e+00  2.5320e-01\n",
      " -7.7042e-01  5.3256e+00  5.2431e-01  ...   2.3777e+00 -2.5513e+00 -2.3114e+00\n",
      "  2.3667e+00 -1.1097e-01 -6.5999e-02  ...  -1.3028e+00 -1.3827e+00 -3.2789e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.0834e+00  4.3420e+00  4.3725e-01  ...   3.1149e+00  1.9649e+00  2.2383e-01\n",
      " -1.9089e-01 -1.7947e+00  1.6055e+00  ...  -2.7149e+00 -2.6868e+00 -5.1451e+00\n",
      " -2.9211e-01 -8.3545e-01 -2.3369e+00  ...  -3.7019e+00 -3.0372e+00 -3.5281e+00\n",
      "     ⋮ \n",
      "\n",
      "(1 ,0 ,.,.) = \n",
      " -2.5753e+00  5.3419e-01 -4.0559e+00  ...  -1.6778e+00  1.3057e+00 -2.1984e+00\n",
      " -6.1441e-01 -1.2188e+00 -3.4997e+00  ...  -5.1200e+00 -3.5176e+00 -1.1166e+00\n",
      " -3.3343e+00 -8.5797e-01 -9.6186e-02  ...  -3.6769e+00 -4.2383e+00 -2.4403e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.4940e+00  2.4392e+00 -2.9094e+00  ...  -6.4245e+00 -3.9802e+00 -3.5123e+00\n",
      "  1.7956e+00  1.4119e+00 -1.1781e+00  ...  -1.4719e+00 -3.8633e+00 -3.4001e+00\n",
      " -8.1034e-01 -1.8883e+00 -2.6205e-02  ...   2.4222e+00 -1.4161e+00 -4.4753e+00\n",
      "     ⋮ \n",
      "\n",
      "(2 ,0 ,.,.) = \n",
      " -1.3151e+00  3.3036e+00  1.1453e+00  ...   5.1035e-01 -2.2287e+00  8.7603e-01\n",
      " -1.5974e+00  1.4517e-01  1.0683e+00  ...  -2.5905e+00 -2.0115e+00 -3.6861e+00\n",
      " -4.8810e-01 -2.9832e+00 -3.9923e+00  ...   3.0719e+00  1.8990e+00  1.0301e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  2.7791e+00 -1.4129e-01 -2.0882e+00  ...   4.3717e+00 -1.0650e+00 -3.2323e+00\n",
      "  3.2678e+00  1.0417e+00  8.2595e-01  ...  -1.2085e+00  1.9294e+00 -5.7686e+00\n",
      "  1.0444e+00  3.3766e+00 -2.1500e+00  ...  -3.2438e+00  2.4422e+00 -4.1548e+00\n",
      "...   \n",
      "     ⋮ \n",
      "\n",
      "(7 ,0 ,.,.) = \n",
      " -5.7561e-01  4.4501e+00 -1.6595e+00  ...   5.0410e+00  1.7056e+00 -2.5921e+00\n",
      "  5.0460e+00  3.6696e+00  1.8101e+00  ...   8.0282e+00  8.3782e+00 -2.8660e+00\n",
      "  5.6974e+00  1.2747e+01  5.7006e+00  ...   6.5666e+00  1.3684e+00  3.8997e+00\n",
      "                 ...                   ⋱                   ...                \n",
      " -6.7832e-01 -4.0958e-01 -3.4134e+00  ...  -2.7911e+00 -4.2008e+00 -2.4782e+00\n",
      " -5.4501e-01 -3.7165e+00 -2.2691e+00  ...   2.1120e-01 -1.3513e+00 -4.8507e+00\n",
      " -2.4688e+00 -3.3659e+00 -4.2693e+00  ...  -4.1948e+00 -3.2888e+00 -5.0494e+00\n",
      "     ⋮ \n",
      "\n",
      "(8 ,0 ,.,.) = \n",
      " -1.5634e+00  4.2139e+00 -1.3950e+00  ...  -3.8988e+00 -2.3697e+00 -5.9041e-01\n",
      "  4.4330e+00  5.2232e+00  7.8708e+00  ...  -3.2896e+00 -2.0291e+00 -1.8411e+00\n",
      "  2.0923e+00  9.3702e-01  4.6442e+00  ...  -4.6926e-01  8.5945e-02 -4.6402e+00\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.3904e+00  7.3894e+00  1.7025e+00  ...  -2.2687e+00 -2.1711e+00 -3.6644e+00\n",
      "  3.8027e+00 -5.4654e+00 -4.9879e-01  ...  -3.4724e+00 -2.7628e+00 -4.6636e+00\n",
      " -7.9890e-01 -2.2426e-01  4.2229e+00  ...  -6.8170e-01 -6.6084e-01 -4.9559e+00\n",
      "     ⋮ \n",
      "\n",
      "(9 ,0 ,.,.) = \n",
      " -1.7105e-01 -2.2648e+00 -6.5051e-01  ...  -1.1389e+00 -4.7389e-01  1.6016e+00\n",
      " -1.4491e+00  1.7804e+00  1.9672e+00  ...  -2.1190e+00 -1.5129e+00  3.3604e+00\n",
      " -1.1033e+00 -1.2170e+00 -2.7895e+00  ...  -3.4296e+00  2.6169e+00  8.5862e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  3.0430e+00 -1.7106e+00 -1.0143e+00  ...  -1.5085e+00 -2.2830e+00 -5.8727e+00\n",
      "  1.6259e+00 -4.7809e+00 -3.8643e+00  ...  -2.1968e+00 -2.7614e+00 -4.3528e+00\n",
      "  6.9775e-01 -8.4900e-01 -4.5141e+00  ...  -2.5067e+00  8.1490e-01 -4.6965e+00\n",
      "[torch.FloatTensor of size 10x1x33x33]\n",
      "\n",
      "Variable containing:\n",
      "nan\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(10, number_classes, 33, 33)\n",
    "b = torch.randn(10, number_classes, 33,33)*0\n",
    "x_train = Variable(a)\n",
    "y_train = Variable(b)\n",
    "\n",
    "x_validation = Variable(b)\n",
    "y_validation = Variable(b)\n",
    "parameters = Parameters( nColumns = 4, learning_rate=0.01, nFeatMaps = [3,6,12,24,48], dropFactor = 0.1)\n",
    "train(parameters = parameters, x_train=x_train, y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroTarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Graphical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'subSamplingSequence' object has no attribute 'Seque'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-e1c0a669babc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m \u001b[0mnetwork\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubSamplingSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnInputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnOutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-e1c0a669babc>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nInputs, nOutputs)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnOutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubSamplingSequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeque\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnInputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/tanguy/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 238\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'subSamplingSequence' object has no attribute 'Seque'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "from torch.autograd import Variable, Function\n",
    "from collections import defaultdict\n",
    "import graphviz\n",
    "\n",
    "\"\"\"\n",
    "This is a rather distorted implementation of graph visualization in PyTorch.\n",
    "This implementation is distorted because PyTorch's autograd is undergoing refactoring right now.\n",
    "- neither func.next_functions nor func.previous_functions can be relied upon\n",
    "- BatchNorm's C backend does not follow the python Function interface\n",
    "- I'm not even sure whether to use var.creator or var.grad_fn (apparently the source tree and wheel builds use different\n",
    "  interface now)\n",
    "As a result, we are forced to manually trace the graph, using 2 redundant mechanisms:\n",
    "- Function.__call__: this allows us to trace all Function creations. Function corresponds to Op in TF\n",
    "- Module.forward_hook: this is needed because the above method doesn't work for BatchNorm, as the current C backend does\n",
    "  not follow the Python Function interface. \n",
    "To do graph visualization, follow these steps:\n",
    "1. register hooks on model: register_vis_hooks(model)\n",
    "2. pass data through model: output = model(input)\n",
    "3. remove hooks           : remove_vis_hooks()\n",
    "4. perform visualization  : save_visualization(name, format='svg') # name is a string without extension\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "old_function__call__ = Function.__call__\n",
    "\n",
    "def register_creator(inputs, creator, output):\n",
    "    \"\"\"\n",
    "    In the forward pass, our Function.__call__ and BatchNorm.forward_hook both call this method to register the creators\n",
    "    inputs: list of input variables\n",
    "    creator: one of\n",
    "        - Function\n",
    "        - BatchNorm module\n",
    "    output: a single output variable\n",
    "    \"\"\"\n",
    "    cid = id(creator)\n",
    "    oid = id(output)\n",
    "    if oid in vars: \n",
    "        return\n",
    "    # connect creator to input\n",
    "    for input in inputs:\n",
    "        iid = id(input)\n",
    "        func_trace[cid][iid] = input\n",
    "        # register input\n",
    "        vars[iid] = input\n",
    "    # connect output to creator\n",
    "    assert type(output) not in [tuple, list, dict]\n",
    "    var_trace[oid][cid] = creator\n",
    "    # register creator and output and all inputs\n",
    "    vars[oid] = output\n",
    "    funcs[cid] = creator\n",
    "\n",
    "hooks = []\n",
    "\n",
    "def register_vis_hooks(model):\n",
    "    global var_trace, func_trace, vars, funcs\n",
    "    remove_vis_hooks()\n",
    "    var_trace  = defaultdict(lambda: {})     # map oid to {cid:creator}\n",
    "    func_trace = defaultdict(lambda: {})     # map cid to {iid:input}\n",
    "    vars  = {}                               # map vid to Variable/Parameter\n",
    "    funcs = {}                               # map cid to Function/BatchNorm module\n",
    "    hooks = []                               # contains the forward hooks, needed for hook removal\n",
    "\n",
    "    def hook_func(module, inputs, output):\n",
    "        assert 'BatchNorm' in mod.__class__.__name__        # batchnorms don't have shared superclass\n",
    "        inputs = list(inputs)\n",
    "        for p in [module.weight, module.bias]:\n",
    "            if p is not None:\n",
    "                inputs.append(p)\n",
    "        register_creator(inputs, module, output)\n",
    "\n",
    "    for mod in model.modules():\n",
    "        if 'BatchNorm' in mod.__class__.__name__:           # batchnorms don't have shared superclass\n",
    "            hook = mod.register_forward_hook(hook_func)\n",
    "            hooks.append(hook)\n",
    "\n",
    "    def new_function__call__(self, *args, **kwargs):\n",
    "        inputs =  [a for a in args            if isinstance(a, Variable)]\n",
    "        inputs += [a for a in kwargs.values() if isinstance(a, Variable)]\n",
    "        output = old_function__call__(self, *args, **kwargs)\n",
    "        register_creator(inputs, self, output)\n",
    "        return output\n",
    "\n",
    "    Function.__call__ = new_function__call__\n",
    "\n",
    "\n",
    "def remove_vis_hooks():\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    Function.__call__ = old_function__call__\n",
    "\n",
    "\n",
    "def save_visualization(name, format='svg'):\n",
    "    g = graphviz.Digraph(format=format)\n",
    "    def sizestr(var):\n",
    "        size = [int(i) for i in list(var.size())]\n",
    "        return str(size)\n",
    "    # add variable nodes\n",
    "    for vid, var in vars.iteritems():\n",
    "        if isinstance(var, nn.Parameter):\n",
    "            g.node(str(vid), label=sizestr(var), shape='ellipse', style='filled', fillcolor='red')\n",
    "        elif isinstance(var, Variable):\n",
    "            g.node(str(vid), label=sizestr(var), shape='ellipse', style='filled', fillcolor='lightblue')\n",
    "        else:\n",
    "            assert False, var.__class__\n",
    "    # add creator nodes\n",
    "    for cid in func_trace:\n",
    "        creator = funcs[cid]\n",
    "        g.node(str(cid), label=str(creator.__class__.__name__), shape='rectangle', style='filled', fillcolor='orange')\n",
    "    # add edges between creator and inputs\n",
    "    for cid in func_trace:\n",
    "        for iid in func_trace[cid]:\n",
    "            g.edge(str(iid), str(cid))\n",
    "    # add edges between outputs and creators\n",
    "    for oid in var_trace:\n",
    "        for cid in var_trace[oid]:\n",
    "            g.edge(str(cid), str(oid))\n",
    "    g.render(name)\n",
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        self.Seque\n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=True)\n",
    "\n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "network = subSamplingSequence(nInputs = 3,nOutputs = 6)\n",
    "print(network)\n",
    "a = torch.randn(2, 3, 7, 7)\n",
    "inputs = Variable(a)\n",
    "out = network(inputs)\n",
    "print(out.size())\n",
    "\n",
    "def visualize(a,network):\n",
    "    global recon\n",
    "    inputs = Variable(a)\n",
    "    register_vis_hooks(network)\n",
    "    recon = network(inputs)\n",
    "    remove_vis_hooks()\n",
    "    save_visualization('pytorch_model', 'png')\n",
    "    \n",
    "visualize(a,network)\n",
    "#resnet18 = models.resnet18()\n",
    "#y = resnet18(inputs)\n",
    "# print(y)\n",
    "\n",
    "g = make_dot(out)\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "import re\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "def make_dot(var):\n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if isinstance(var, Variable):\n",
    "                value = '('+(', ').join(['%d'% v for v in var.size()])+')'\n",
    "                dot.node(str(id(var)), str(value), fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'previous_functions'):\n",
    "                for u in var.previous_functions:\n",
    "                    dot.edge(str(id(u[0])), str(id(var)))\n",
    "                    add_nodes(u[0])\n",
    "    add_nodes(var.creator)\n",
    "    return dot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
