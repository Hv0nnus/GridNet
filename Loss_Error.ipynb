{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the loss function between the y_train_estimated and y_train\n",
    "    (0) = y_estimated : result of train(x) which is the forward action\n",
    "    (1) = y : Label associated with x\n",
    "\"\"\"\n",
    "def criterion(y_estimated, y):\n",
    "    y[0,0,:] = parameters.number_classes - 1\n",
    "    nllcrit = nn.NLLLoss()\n",
    "    print(\"y\")\n",
    "    print(y)\n",
    "    print(\"y_estimated\")\n",
    "    print(y_estimated)\n",
    "\n",
    "    y_only_usefull_class = (y != (parameters.number_classes - 1))\n",
    "    y_only_usefull_class = y_only_usefull_class.unsqueeze(1)\n",
    "    y_only_useless_class = (y == (parameters.number_classes - 1))\n",
    "    y_only_useless_class = y_only_useless_class\n",
    "\n",
    "    y_estimated = y_estimated * y_only_usefull_class.float()\n",
    "\n",
    "    y_estimated[:,parameters.number_classes - 1,:,:] = y_only_useless_class.float()\n",
    "    print(\"y_estimated\")\n",
    "    print(y_estimated)\n",
    "\n",
    "    y_estimated = F.log_softmax(y_estimated, dim = 1)\n",
    "    #y_estimated_softmax_copy = y_estimated_softmax\n",
    "    #y_estimated_softmax[:,parameters.number_classes - 1,:,:] = 1\n",
    "    return nllcrit(y_estimated, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Define the loss function between the y_train_estimated and y_train and return a vector with the epoch the value\n",
    "    and if the criterion is used on training or validation set.\n",
    "    (0) = y_estimated : result of train(x) which is the forward action\n",
    "    (1) = y : Label associated with x\n",
    "    (2) = epoch : the actual epoch of the learning\n",
    "    (3) = Set : string which is train of validation\n",
    "\"\"\"\n",
    "def criterion_pd_format(y_estimated, y, epoch, Set):\n",
    "    nllcrit = nn.NLLLoss2d()\n",
    "    loss = nllcrit(F.log_softmax(y_estimated, dim = 1), y)\n",
    "    return ([epoch, loss.data[0], Set, epoch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Test function : IoU\n",
    "    Return a matrix of confusion in a good format to creat a pandas DataFrame\n",
    "    (0) = y_estimated : result of train(x) which is the forward action\n",
    "    (1) = y : Label associated with x\n",
    "    (2) = epoch : the actual epoch of the learning\n",
    "    (3) = Set : string which is train of validation\n",
    "\"\"\"\n",
    "def IoU_pd_format(y_estimated, y, Set, epoch):\n",
    "    \n",
    "    #We keep only the higest value, which is the prediction\n",
    "    pred = torch.max(y_estimated, dim=1)[1]\n",
    "\n",
    "    #Creat the confusion matrix, only the second column will have the value\n",
    "    confusion_matrix = [[0] * 6 for i in range(parameters.number_classes**2)]\n",
    "    \n",
    "    pred = pred.view(-1)\n",
    "    target = y_train.view(-1)\n",
    "\n",
    "    # We will normalise the value in the matrix. We don t want to be influence by the size of the batch\n",
    "    normalisation_value = y.size()\n",
    "    # It is also possible to add the size of the image to normalise\n",
    "    normalisation_value = normalisation_value[0]# * normalisation_value[1] * normalisation_value[2]\n",
    "    \n",
    "    # Double loop over the number of classes at each iteration we add the intersection\n",
    "    # i will be the number of iteration\n",
    "    i = 0\n",
    "    for cls1 in range(parameters.number_classes):\n",
    "        pred_inds = pred == cls1\n",
    "        \n",
    "        for cls2 in range(parameters.number_classes):\n",
    "            \n",
    "            i = cls1*parameters.number_classes + cls2\n",
    "            \n",
    "            target_inds = target == cls2\n",
    "            # Intersection is the value predicted of class cls2 and are in reality class cls1\n",
    "            intersection = (pred_inds*target_inds).long().sum().data.cpu()[0]\n",
    "            \n",
    "            #First line is index that will be usefull for the dataFrame\n",
    "            confusion_matrix[i][0] = i + epoch * parameters.number_classes * parameters.number_classes\n",
    "            # Traning or validation set\n",
    "            confusion_matrix[i][1] = Set\n",
    "            # The value normalised\n",
    "            confusion_matrix[i][2] = intersection/normalisation_value\n",
    "            # Associated with this value we keep the two classes\n",
    "            confusion_matrix[i][3] = \"class\" + str(cls1)\n",
    "            confusion_matrix[i][4] = \"class\" + str(cls2)\n",
    "            # The epoch associated\n",
    "            confusion_matrix[i][5] = epoch\n",
    "\n",
    "    return(confusion_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
