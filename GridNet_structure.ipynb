{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "firstConv(\n",
      "  (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class firstConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input which is also the same for the output\n",
    "    This is the first convolution used to enter into the grid.\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs):\n",
    "        super(firstConv, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nInputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = nInputs, out_channels = nInputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        #self.batch2 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        #self.ReLU2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv2(x)\n",
    "        #x = self.batch2(x)\n",
    "        #x = self.ReLU2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "#net = firstConv(nInputs = 3)\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convSequence(\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class convSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    (3) = dropFactor : Total Dropout on the entire Sequence, there is a probability p = dropFactor that\n",
    "        the residual is deleted.\n",
    "    This class represent a residual bloc that doesn't change the number nor the size of the features maps\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs,dropFactor):\n",
    "        super(convSequence, self).__init__()\n",
    "        \n",
    "        self.dropFactor = dropFactor\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x_init):\n",
    "        x = self.batch1(x_init)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = self.conv2(x)\n",
    "        # *1 is a small trick that transform boolean into integer\n",
    "        x = ((random.random() > self.dropFactor) * 1) * x\n",
    "        x = x_init + x\n",
    "        return x\n",
    "\n",
    "    \n",
    "#net = convSequence(nInputs = 3,nOutputs = 3,dropFactor = 0.1)\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subSamplingSequence(\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class subSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that reduce the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(subSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=False)        \n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "#network = subSamplingSequence(nInputs = 3,nOutputs = 6)\n",
    "#print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upSamplingSequence(\n",
      "  (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU1): ReLU()\n",
      "  (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (ReLU2): ReLU()\n",
      "  (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class upSamplingSequence(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features map for the input\n",
    "    (2) = nOutput : number of features map for the output\n",
    "    This class represente a bloc that increase the resolution of each feature map(factor2)\n",
    "    \"\"\"\n",
    "    def __init__(self, nInputs, nOutputs):\n",
    "        super(upSamplingSequence, self).__init__()\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        self.ReLU1 = nn.ReLU()\n",
    "\n",
    "        self.convTranspose1 = nn.ConvTranspose2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(2,2), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "        \n",
    "        self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.convTranspose1(x)\n",
    "        x = self.batch2(x)\n",
    "        x = self.ReLU2(x)\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#network = upSamplingSequence(nInputs = 6,nOutputs = 3)\n",
    "#print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lastConv(\n",
      "  (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False)\n",
      "  (ReLU1): ReLU()\n",
      "  (conv1): Conv2d (3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (batch2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class lastConv(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInputs : number of features map for the input\n",
    "    (2) = nOutputs : number of features map for the output\n",
    "    This class represente the last Convolution of the network before the prediction\n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs,nOutputs):\n",
    "        super(lastConv, self).__init__()\n",
    "\n",
    "\n",
    "        \n",
    "        self.batch1 = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=False)\n",
    "        \n",
    "        self.ReLU1 = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = nInputs, out_channels = nOutputs,\n",
    "                            kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "        self.batch2 = nn.BatchNorm2d(num_features = nOutputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "                \n",
    "        #self.ReLU2 = nn.ReLU()\n",
    "\n",
    "        #self.conv2 = nn.Conv2d(in_channels = nOutputs, out_channels = nOutputs,\n",
    "        #                    kernel_size = (3,3), stride=(1,1), padding=(1,1), dilation=1, groups=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)\n",
    "        x = self.ReLU1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch2(x)\n",
    "        #x = self.ReLU2(x)\n",
    "        #x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "#net = lastConv(nInputs = 3,nOutputs = 20)\n",
    "#print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gridNet(\n",
      "  (batchNormInitial): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (firstConv): firstConv(\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "  )\n",
      "  (convSequence0_0to0_1): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence0_0to1_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence0_1to0_2): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence0_1to1_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence0_2to0_3): convSequence(\n",
      "    (batch1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence1_0to1_1): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence1_0to2_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence1_1to1_2): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence1_1to2_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence1_2to1_3): convSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upSamplingSequence1_2to0_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (upSamplingSequence1_3to0_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (convSequence2_0to2_1): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence2_0to3_0): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence2_1to2_2): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (subSamplingSequence2_1to3_1): subSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence2_2to2_3): convSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upSamplingSequence2_2to1_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (upSamplingSequence2_3to1_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (6, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (convSequence3_0to3_1): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence3_1to3_2): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (convSequence3_2to3_3): convSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv1): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (upSamplingSequence3_2to2_2): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (upSamplingSequence3_3to2_3): upSamplingSequence(\n",
      "    (batch1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU1): ReLU()\n",
      "    (convTranspose1): ConvTranspose2d (24, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (batch2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (ReLU2): ReLU()\n",
      "    (conv2): Conv2d (12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (lastConv): lastConv(\n",
      "    (conv1): Conv2d (3, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch1): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=False)\n",
      "    (ReLU1): ReLU()\n",
      "    (conv2): Conv2d (19, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (batch2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (logsoftmax1): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class gridNet(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    (1) = nInput : number of features maps for the input\n",
    "    (2) = nOutput : number of features maps for the output\n",
    "    (3) = nColumns : number of columns of the gridNet, this number should be divisible by two.\n",
    "    It count the number of bloc +1\n",
    "    (4) = nFeatMaps : number of feature at each row of the gridNet\n",
    "    (5) = dropFactor : factor witch control the dropout of an entire bloc \n",
    "    \"\"\"\n",
    "    def __init__(self,nInputs, nOutputs, nColumns, nFeatMaps, dropFactor):\n",
    "        super(gridNet, self).__init__()\n",
    "        \n",
    "        #Define some parameters as an attribut of the class\n",
    "        len_nfeatureMaps = len(nFeatMaps)\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        self.len_nfeatureMaps = len_nfeatureMaps\n",
    "        \n",
    "        # A normalisation before any computation\n",
    "        self.batchNormInitial = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0.1,affine=True)\n",
    "\n",
    "        # The first convolution before entering into the grid.\n",
    "        self.firstConv = firstConv(nInputs = nInputs)\n",
    "        \n",
    "        \n",
    "        # We create the Grid. We will creat conv and sub/up sequences with different name.\n",
    "        # The name is : \"sequenceName\" + starting position of the sequence(i,j) + \"to\" + ending position (k,l)\n",
    "        for i in range(len(nFeatMaps)):\n",
    "            for j in range(nColumns):\n",
    "                #We don t creat a residual bloc on the last column\n",
    "                if(j < (nColumns - 1)):\n",
    "                    setattr(self, \"convSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j + 1),\n",
    "                            convSequence(nFeatMaps[i], nFeatMaps[i],dropFactor))\n",
    "                \n",
    "                #We creat subSampling only on half of the grid and not in the last row\n",
    "                if(j < (nColumns // 2) and i < (len(nFeatMaps)-1)):\n",
    "                    setattr(self, \"subSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i + 1) + \"_\" + str(j),\n",
    "                            subSamplingSequence(nFeatMaps[i], nFeatMaps[i+1]))\n",
    "                \n",
    "                #Welook a the other half but not the first row\n",
    "                if(j >= (nColumns // 2) and i > 0):\n",
    "                    setattr(self, \"upSamplingSequence\" + str(i) + \"_\" + str(j) + \"to\" + str(i - 1) + \"_\" + str(j),\n",
    "                            upSamplingSequence(nFeatMaps[i], nFeatMaps[i-1]))\n",
    "\n",
    "        # The last convolution before the result.\n",
    "        self.lastConv = lastConv(nInputs = nFeatMaps[0], nOutputs = nOutputs)    \n",
    "        \n",
    "        #self.batchNormFinal = nn.BatchNorm2d(num_features = nInputs, eps=1e-05, momentum=0,affine=True)\n",
    "        \n",
    "        self.logsoftmax1 = nn.LogSoftmax()\n",
    "        \n",
    "        \n",
    "    \n",
    "    \"\"\"This function return the fusion of the actual value on (i,j) and the new data which come from the sampling\n",
    "    (1) = X_i_j : The value on the grid a the position (i,j)\n",
    "    (2) = SamplingSequence : The sampling that should be added to the point (i,j)\n",
    "    \"\"\"\n",
    "    def addTransform(self,X_i_j,SamplingSequence):\n",
    "        return(X_i_j + SamplingSequence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # A normalisation before any computation\n",
    "        x = self.batchNormInitial(x)\n",
    "        # The first convolution before entering into the grid.\n",
    "        x = self.firstConv(x)\n",
    "        \n",
    "        # X is the matrix that represente the values of the features maps at the point (i,j) in the grid.\n",
    "        X = [[0 for i in range(self.nColumns)] for j in range(self.len_nfeatureMaps)]\n",
    "        #The input of the grid is on (0,0)\n",
    "        X[0][0] = x\n",
    "        \n",
    "        # Looking on half of the grid, with sumsampling and convolution sequence\n",
    "        for j in range(self.nColumns//2):\n",
    "            for i in range(self.len_nfeatureMaps):\n",
    "                #For the first column, there is only subsampling\n",
    "                if(j > 0):\n",
    "                    #This syntaxe call self.conSequencei_(j-1)toi_j(X[i][j-1])\n",
    "                    X[i][j] = getattr(self,\"convSequence\"\n",
    "                                      + str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "                \n",
    "                # For the first row, there is only ConvSequence (residual bloc)\n",
    "                if(i > 0):\n",
    "                    X[i][j] = self.addTransform(X[i][j] , getattr(self,\"subSamplingSequence\"\n",
    "                                                + str(i-1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i-1][j]))\n",
    "\n",
    "        # Looking on the other half of the grid\n",
    "        for j in range(self.nColumns//2,self.nColumns):\n",
    "            for i in range(self.len_nfeatureMaps-1,-1,-1):\n",
    "                X[i][j] = getattr(self,\"convSequence\" +\n",
    "                                      str(i) + \"_\" + str(j-1) + \"to\" + str(i) + \"_\" + str(j))(X[i][j-1])\n",
    "\n",
    "                \n",
    "                # There is no upSampling on the last row\n",
    "                if(i < (self.len_nfeatureMaps - 1)):\n",
    "                    X[i][j] = self.addTransform(X[i][j], getattr(self,\"upSamplingSequence\"\n",
    "                                                + str(i+1) + \"_\" + str(j) + \"to\" + str(i) + \"_\" + str(j))(X[i+1][j]))\n",
    "\n",
    "        x_final = self.lastConv(X[0][self.nColumns - 1])\n",
    "\n",
    "        if(False):\n",
    "            print(\"Size of different X_i_j\")\n",
    "            for i1,i2 in enumerate(X):\n",
    "                for j1,j2 in enumerate(i2):\n",
    "                    print(\"Dim(X(\" + str(i1) + \")(\" + str(j1) + \")) : \",j2.size())\n",
    "             \n",
    "\n",
    "        return x_final\n",
    "\n",
    "\n",
    "#network = gridNet(nInputs = 3,nOutputs = 19, nColumns = 4, nFeatMaps = [3,6,12,24], dropFactor = 0.1)\n",
    "#print(network)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
