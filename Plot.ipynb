{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns; sns.set()\n",
    "from ggplot import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"organise_CSV import two CSV files and delete all duplicate row. Because the algorithme work with\n",
    "    mini_batch there is many value for the loss for one epoch and one data set. We compute here the mean\n",
    "    of all this loss that have the same epoch and data set. We did the same with the confusion matrix\n",
    "    (0) = name_network : name of the network associated with the CSV file\n",
    "    (1) = train_number : number of the network associated with the CSV file\n",
    "\"\"\"\n",
    "def organise_CSV(path_CSV,name_network,train_number):\n",
    "    # Import the CSV file into pandas DataFrame\n",
    "    loss_DF = pd.read_csv(path_CSV + \"CSV_loss_\" + name_network + str(train_number) + \".csv\")\n",
    "    # This Groupby will regroupe all line that have the same \"Set\" and \"Epoch\" and compute the mean over the \"Values\"\n",
    "    loss_DF = loss_DF.groupby(['Set','Epoch'])['Value'].mean().reset_index()\n",
    "    # Recreate the CSV file\n",
    "    loss_DF.to_csv(path_CSV + \"CSV_loss_\" + name_network + str(train_number) + \".csv\",index = False)\n",
    "    \n",
    "    # Import the CSV file into pandas DataFrame\n",
    "    conf_DF = pd.read_csv(path_CSV + \"CSV_confMat_\" + name_network + str(train_number) + \".csv\")\n",
    "    # This Groupby will regroupe all line that have the same 'Target','Prediction','Epoch','Set'\n",
    "    # and compute the mean over the \"Values\"\n",
    "    conf_DF = conf_DF.groupby(['Target','Prediction','Epoch','Set'])['Value'].mean().reset_index()\n",
    "    # Recreate the CSV file\n",
    "    conf_DF.to_csv(path_CSV + \"CSV_confMat_\" + name_network + str(train_number) + \".csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plot_loss will plot the loss against the epoch\n",
    "    (0) = name_network : name of the network associated with the CSV file\n",
    "    (1) = train_number : number of the network associated with the CSV file\n",
    "\"\"\"\n",
    "def plot_loss(path_CSV,name_network,train_number):\n",
    "    # Import the CSV file into pandas DataFrame\n",
    "    loss_DF = pd.read_csv(path_CSV + \"CSV_loss_\" + name_network + str(train_number) + \".csv\")\n",
    "    \n",
    "    # Epoch against Value with a different color for train and validation\n",
    "    my_plot_loss = ggplot(aes(x=\"Epoch\", y=\"Value\",color = \"Set\"),data = loss_DF)\n",
    "    my_plot_loss = my_plot_loss + geom_line() \n",
    "    my_plot_loss = my_plot_loss + ggtitle(\"Loss per epoch\")\n",
    "    my_plot_loss = my_plot_loss + ylab(\"Loss\")\n",
    "    print(my_plot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plot_IuO will plot the loss against the epoch\n",
    "    (0) = name_network : name of the network associated with the CSV file\n",
    "    (1) = train_number : number of the network associated with the CSV file\n",
    "\"\"\"\n",
    "def plot_IuO(path_CSV,name_network,train_number):\n",
    "    # Import the CSV of the conv matrix\n",
    "    conf_DF = pd.read_csv(path_CSV + \"CSV_confMat_\" + name_network + str(train_number) + \".csv\")\n",
    "    \n",
    "    # Delete the class 19\n",
    "    conf_DF_uselfull_classes = conf_DF[(conf_DF[\"Prediction\"] != \"class\"+str(parameters.number_classes - 1)) \n",
    "                                       & (conf_DF[\"Target\"] != \"class\"+str(parameters.number_classes - 1))]\n",
    "    # In the column \"Value\" there is the TP information\n",
    "    conf_DF_TP = conf_DF_uselfull_classes[conf_DF_uselfull_classes[\"Prediction\"] == conf_DF_uselfull_classes[\"Target\"]]\n",
    "\n",
    "    # In the column \"Value\" there is the FN information\n",
    "    conf_DF_FN = conf_DF_uselfull_classes.groupby([\"Set\",\"Epoch\",\"Target\"])[\"Value\"].sum().reset_index()\n",
    "    # In the column \"Value\" there is the FP information\n",
    "    conf_DF_FP = conf_DF_uselfull_classes.groupby([\"Set\",\"Epoch\",\"Prediction\"])[\"Value\"].sum().reset_index()\n",
    "\n",
    "    # Change the name\n",
    "    conf_DF_FN.rename(columns={\"Value\": \"FN\"}, inplace=True)\n",
    "    conf_DF_FP.rename(columns={\"Value\": \"FP\"}, inplace=True)\n",
    "\n",
    "    # Merge the dataset together according to certain column\n",
    "    conf_DF_TP_FN = conf_DF_TP.merge(conf_DF_FN, on=[\"Epoch\",\"Set\",\"Target\"])\n",
    "    conf_DF_TP_FN_FP = conf_DF_TP_FN.merge(conf_DF_FP, on=[\"Epoch\",\"Set\",\"Prediction\"])\n",
    "    \n",
    "    # We compute the realFP and FN value, we have to substract the TP values\n",
    "    conf_DF_TP_FN_FP[\"FP\"] = conf_DF_TP_FN_FP[\"FP\"] - conf_DF_TP_FN_FP[\"Value\"]\n",
    "    conf_DF_TP_FN_FP[\"FN\"] = conf_DF_TP_FN_FP[\"FN\"] - conf_DF_TP_FN_FP[\"Value\"]\n",
    "    \n",
    "    # Compute the IoU each class\n",
    "    conf_DF_TP_FN_FP[\"IoU\"] = conf_DF_TP_FN_FP[\"Value\"]/(conf_DF_TP_FN_FP[\"Value\"] + \n",
    "                                                         conf_DF_TP_FN_FP[\"FP\"] + conf_DF_TP_FN_FP[\"FN\"])\n",
    "\n",
    "    # Compute the mean IoU\n",
    "    plot_DF = conf_DF_TP_FN_FP.groupby([\"Set\",\"Epoch\"])[\"IoU\"].mean().reset_index()\n",
    "\n",
    "    #Add the real name of Data.\n",
    "    \n",
    "    # Plot the IuO mean\n",
    "    my_plot_IoU = ggplot(aes(x=\"Epoch\", y=\"IoU\",color = \"Set\"),data = plot_DF) + geom_line()\n",
    "    my_plot_IoU = my_plot_IoU + ggtitle(\"Mean IoU per epoch\")\n",
    "    my_plot_IoU = my_plot_IoU + ylab(\"Mean IoU\")\n",
    "    print(my_plot_IoU)\n",
    "    \n",
    "    #Change change the name of class for the plot\n",
    "    conf_DF_TP_FN_FP = conf_DF_TP_FN_FP.merge(parameters.label_DF, left_on='Target', right_on='Class_name')\n",
    "\n",
    "    # Plot the IuO per class only train\n",
    "    my_plot_IoU = ggplot(aes(x=\"Epoch\", y=\"IoU\",color = \"Real_name\"),\n",
    "                          data = conf_DF_TP_FN_FP[conf_DF_TP_FN_FP[\"Set\"] == \"train\"]) + geom_line()\n",
    "    my_plot_IoU = my_plot_IoU + ggtitle(\"Train IoU per epoch\")\n",
    "    my_plot_IoU = my_plot_IoU + ylab(\"Train IoU\")\n",
    "    print(my_plot_IoU)\n",
    "    \n",
    "    # Plot the IuO per class only validation\n",
    "    my_plot_IoU = ggplot(aes(x=\"Epoch\", y=\"IoU\",color = \"Real_name\"),\n",
    "                          data = conf_DF_TP_FN_FP[conf_DF_TP_FN_FP[\"Set\"] == \"validation\"]) + geom_line()\n",
    "    my_plot_IoU = my_plot_IoU + ggtitle(\"Validation IoU per epoch\")\n",
    "    my_plot_IoU = my_plot_IoU + ylab(\"Validation IoU\")\n",
    "    print(my_plot_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"plot_IuO will plot confusion matrix\n",
    "    (0) = name_network : name of the network associated with the CSV file\n",
    "    (1) = train_number : number of the network associated with the CSV file\n",
    "    (2) = epoch : Value of the epoch were we want to display the confusion matrix\n",
    "    (3) = data_set : \n",
    "\"\"\"\n",
    "def plot_mat_confusion(path_CSV,name_network,train_number,epoch,data_set):\n",
    "    \n",
    "    # Import the CSV as DataFrame\n",
    "    conf_DF = pd.read_csv(path_CSV + \"CSV_confMat_\" + name_network + str(train_number) + \".csv\")\n",
    "    # Select only the usefull epoch\n",
    "    conf_DF = conf_DF[conf_DF[\"Epoch\"]==epoch]\n",
    "    # Keep only the DataSet to display\n",
    "    conf_DF = conf_DF[conf_DF[\"Set\"]==data_set]\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_mat_for_plot = np.zeros((parameters.number_classes,parameters.number_classes))\n",
    "    #Double loop over the confusion matrix the ad each value\n",
    "    for i in range(parameters.number_classes):\n",
    "        for j in range(parameters.number_classes):\n",
    "            conf_mat_for_plot[i,j] = conf_DF.loc[(conf_DF[\"Prediction\"]==(\"class\"+str(i))) &\n",
    "                                                 (conf_DF[\"Target\"]==(\"class\"+str(j))),\"Value\"].values\n",
    "    \n",
    "    #Just change column and row name to make good plot and make the confusion matrix a dataframe\n",
    "    conf_mat_for_plot=pd.DataFrame(conf_mat_for_plot, columns = [\"road\",\"sidewalk\",\"building\",\"wall\",\"fence\",\n",
    "                                                                        \"pole\",\"traffic light\",\"traffic sign\",\n",
    "                                                                        \"vegetation\",\"terrain\",\"sky\",\"person\",\"rider\",\n",
    "                                                                        \"car\",\"truck\",\"bus\",\"train\",\"motorcycle\",\n",
    "                                                                        \"bicycle\"])\n",
    "    # Rename the rows\n",
    "    conf_mat_for_plot = conf_mat_for_plot.rename({0 : \"road\", 1 : \"sidewalk\", 2 : \"building\", 3 : \"wall\",4 : \"fence\",\n",
    "                                                  5 : \"pole\",6 : \"traffic light\",7 : \"traffic sign\", 8 : \"vegetation\",\n",
    "                                                  9 : \"terrain\",10 : \"sky\" ,11 : \"person\" ,12 : \"rider\", 13 :\"car\",\n",
    "                                                  14 : \"truck\",15 : \"bus\",16 : \"train\",17 : \"motorcycle\",\n",
    "                                                  18 : \"bicycle\"},axis='index')\n",
    "    # Set the size\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(15, 15)\n",
    "    sns.heatmap(conf_mat_for_plot,annot=True,ax=ax,square = True,cmap = \"Reds\")\n",
    "    plt.xlabel(r'Prediction',fontsize = 20)\n",
    "    plt.ylabel(r'Real class',fontsize = 20)\n",
    "    plt.title(\"Confusion matrix of \" + data_set + \"set for epoch \" + str(epoch), fontsize = 20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self,\n",
    "                 # Number of columns of the grid\n",
    "                 nColumns = 2,\n",
    "                 # Number of features map at each rows\n",
    "                 nFeatMaps = [3,6],\n",
    "                 # Number of feature map of the input image\n",
    "                 nFeatureMaps_init = 3,\n",
    "                 #Number of classes (19(usefull classes) + 1(all other classes together))\n",
    "                 number_classes = 20,\n",
    "                 # DataFrame with the name of each label associated with their number\n",
    "                 label_DF = None,\n",
    "\n",
    "                 # Size of initial image\n",
    "                 width_image_initial = 2048, height_image_initial = 1024,\n",
    "                 # Size after the crop\n",
    "                 width_image_crop = 19, height_image_crop = 19,\n",
    "\n",
    "                 # Probability of a Blockwise dropout\n",
    "                 dropFactor = 0.1,\n",
    "                 learning_rate=0.01,\n",
    "                 weight_decay = 5*10**(-6),\n",
    "                 #Parameter of the Adam Optimizer (beta1 beta2 and epsilon)\n",
    "                 beta1 = 0.9,\n",
    "                 beta2 = 0.999,\n",
    "                 epsilon = 1*10**(-8),\n",
    "                 # Size of the mini batch\n",
    "                 batch_size = 2,\n",
    "                 # Size of the mini batch to compute error (if the entire validation set cannot be in loaded)\n",
    "                 batch_size_val = 10,\n",
    "                 # Maximum value of epoch iteration\n",
    "                 epoch_total = 10,\n",
    "                 # The actual epoch is not null if we train the network which has already been train\n",
    "                 actual_epoch = 0,\n",
    "\n",
    "                 # File where all the parameter model can be store\n",
    "                 path_save_net = \"Model/\",\n",
    "                 #Name of the network, used for store (name_network and train_number)\n",
    "                 name_network = \"test\",\n",
    "                 train_number = 0,\n",
    "                 # File where the error will be stored\n",
    "                 path_CSV = \"CSV/\",\n",
    "                 # Path of the Data\n",
    "                 path_data = \"Cityscapes_Copy/\",\n",
    "                 # Number of process that will load the Data\n",
    "                 num_workers = 0):\n",
    "        \n",
    "        super(Parameters, self).__init__()\n",
    "        # Image\n",
    "        self.number_classes = number_classes\n",
    "        self.label_DF = label_DF\n",
    "        self.width_image_initial = width_image_initial\n",
    "        self.height_image_initial = height_image_initial\n",
    "        self.width_image_crop = width_image_crop\n",
    "        self.height_image_crop = height_image_crop\n",
    "        # Number of feature map at the begining, if RGB image it would be 3\n",
    "        self.nFeatureMaps_init = nFeatureMaps_init\n",
    "        self.path_data = path_data\n",
    "        \n",
    "        # GridNet\n",
    "        self.nColumns = nColumns\n",
    "        self.nFeatMaps = nFeatMaps\n",
    "        self.name_network = name_network\n",
    "        self.train_number = train_number\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        #Save\n",
    "        self.path_CSV = path_CSV\n",
    "        self.path_save_net = path_save_net\n",
    "        \n",
    "        \n",
    "        # Learning\n",
    "        self.dropFactor = dropFactor\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_val = batch_size_val\n",
    "        self.epoch_total = epoch_total\n",
    "        self.actual_epoch = actual_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'Model/best0test0checkpoint.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "def load_from_checkpoint(path_checkpoint):\n",
    "    if (os.path.isfile(path_checkpoint)):\n",
    "        print(\"=> loading checkpoint '{}'\".format(path_checkpoint))        \n",
    "        checkpoint = torch.load(path_checkpoint)\n",
    "        parameters = checkpoint['parameters']\n",
    "        return(parameters)\n",
    "    else:\n",
    "        return(\"cocou\")\n",
    "\n",
    "path_checkpoint = \"Model/best0test0checkpoint.pth.tar\"\n",
    "\n",
    "parameters = load_from_checkpoint(path_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "organise_CSV(path_CSV = parameters.path_CSV,\n",
    "             name_network = parameters.name_network,train_number = parameters.train_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30e6f993b241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plot_loss(path_CSV = parameters.path_CSV,\n\u001b[0m\u001b[1;32m      2\u001b[0m          name_network = parameters.name_network,train_number = parameters.train_number)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m plot_IuO(path_CSV = parameters.path_CSV,\n\u001b[1;32m      5\u001b[0m          name_network = parameters.name_network,train_number = parameters.train_number)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_loss' is not defined"
     ]
    }
   ],
   "source": [
    "plot_loss(path_CSV = parameters.path_CSV,\n",
    "         name_network = parameters.name_network,train_number = parameters.train_number)\n",
    "\n",
    "plot_IuO(path_CSV = parameters.path_CSV,\n",
    "         name_network = parameters.name_network,train_number = parameters.train_number)\n",
    "\n",
    "plot_mat_confusion(path_CSV = parameters.path_CSV,\n",
    "                   name_network = parameters.name_network, train_number = parameters.train_number,\n",
    "                   epoch = parameters.epoch_total - 1, data_set = \"train\")\n",
    "\n",
    "plot_mat_confusion(path_CSV = parameters.path_CSV,name_network = parameters.name_network,\n",
    "                   train_number = parameters.train_number,\n",
    "                   epoch = parameters.epoch_total - 1,data_set = \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
